"""
ðŸ’° SUPPORT THIS RESEARCH - PLEASE DONATE! ðŸ’°

ðŸ™ If this library helps your research or project, please consider donating:
ðŸ’³ PayPal: https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=WXQKYYKPHWXHS
â­ GitHub Sponsors: https://github.com/sponsors/benedictchen

ðŸ‘¨â€ðŸ’» Author: Benedict Chen
ðŸ’° Donations: Help support this work! Buy me a coffee â˜•, beer ðŸº, lamborghini ðŸŽï¸, or private island ðŸï¸
ðŸ’– Please consider recurring donations to fully support continued research

Your support enables cutting-edge AI research for everyone! ðŸš€

Continual Meta-Learning Implementation ðŸ§ ðŸ’­
==========================================

ðŸŽ¯ **ELI5 Explanation**:
Imagine you're a student who needs to keep learning new subjects without forgetting the old ones!
Regular learning is like cramming for one test and then forgetting everything for the next test.
Continual meta-learning is like being a super-student who:
- ðŸ§  **Remembers important lessons** from past subjects (no catastrophic forgetting)
- âš¡ **Learns new subjects quickly** using patterns from previous learning
- ðŸ’¡ **Gets better at learning itself** over time across all subjects

ðŸ“Š **Continual Learning Challenge Visualization**:
```
Traditional Learning:           Continual Meta-Learning:
Task A â†’ Forget A              Task A â”€â”€â”€â”€â†’ Remember A
Task B â†’ Forget B      VS      Task B â”€â”€â”€â”€â†’ Remember A+B  
Task C â†’ Forget C              Task C â”€â”€â”€â”€â†’ Remember A+B+C
```

ðŸ”¬ **Research Foundation**:
- **Elastic Weight Consolidation**: James Kirkpatrick et al. (Nature 2017) - "Overcoming catastrophic forgetting"
- **Online Meta-Learning**: Chelsea Finn et al. (ICML 2019) - "Online Meta-Learning"
- **Episodic Memory Networks**: Andrea Banino et al. (Nature 2018) - "Vector-based episodic memory"
- **Task-Agnostic Meta-Learning**: Sungyong Seo et al. (NeurIPS 2020)

ðŸ§® **Key Mathematical Components**:
- **EWC Loss**: L = L_task + Î» Î£áµ¢ Fáµ¢(Î¸áµ¢ - Î¸áµ¢*)Â²  [Prevents forgetting important parameters]
- **Fisher Information**: Fáµ¢ = ð”¼[âˆ‡log p(x|Î¸)]Â²  [Measures parameter importance]
- **Meta-Gradient**: âˆ‡Î¸ = âˆ‡L_new - Î»âˆ‡L_consolidation  [Balances new vs old knowledge]

Algorithms implemented:
1. Online Meta-Learning with Memory Banks
2. Continual MAML with Elastic Weight Consolidation (James Kirkpatrick et al. 2017)
3. Meta-Learning with Episodic Memory Networks  
4. Gradient-Based Continual Meta-Learning
5. Task-Agnostic Meta-Learning for Continual Adaptation
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Tuple, Optional, Any, Deque
import numpy as np
from dataclasses import dataclass
import logging
from collections import deque, defaultdict
import copy
import pickle
from .core.math_utils import pairwise_sqeuclidean, cosine_logits

logger = logging.getLogger(__name__)


@dataclass
class ContinualMetaConfig:
    """Base configuration for continual meta-learning with research-accurate options."""
    # Core configuration
    memory_size: int = 1000
    adaptation_lr: float = 0.01
    meta_lr: float = 0.001
    forgetting_factor: float = 0.99
    consolidation_strength: float = 1000.0
    replay_frequency: int = 10
    temperature: float = 1.0
    
    # RESEARCH-ACCURATE CONFIGURATION OPTIONS:
    
    # EWC variant selection
    ewc_method: str = "diagonal"  # "diagonal", "full", "evcl", "none"
    
    # Fisher Information computation options (Kirkpatrick et al. 2017)
    fisher_samples: int = 10000  # Number of samples to compute Fisher Information
    fisher_alpha: float = 0.5    # EMA coefficient for Fisher Information updates
    
    # Memory replay mechanisms
    replay_strategy: str = "reservoir"  # "reservoir", "herding", "cluster", "random"
    episodic_memory: bool = True       # Use episodic memory networks
    
    # Online adaptation parameters
    online_updates: bool = True        # Enable online parameter updates
    adaptation_steps: int = 5          # Number of adaptation steps per task
    use_higher_order_grads: bool = True  # Enable second-order meta gradients


class FisherInformationMatrix:
    """
    Fisher Information Matrix computation for Elastic Weight Consolidation.
    
    Implements multiple variants:
    - Diagonal approximation (Kirkpatrick et al. 2017)
    - Full Fisher Information Matrix
    - Empirical Fisher (Pascanu & Bengio 2014) 
    """
    
    def __init__(self, model: nn.Module, method: str = "diagonal"):
        self.model = model
        self.method = method
        self.fisher_dict = {}
        self.param_importance = {}
        
    def compute_fisher(self, dataloader, num_samples: int = 10000):
        """
        Compute Fisher Information Matrix using log-likelihood gradients.
        
        F_ii = E[âˆ‚Â²/âˆ‚Î¸áµ¢Â² log p(D|Î¸)] â‰ˆ E[(âˆ‚/âˆ‚Î¸áµ¢ log p(D|Î¸))Â²]
        """
        logger.info(f"Computing Fisher Information Matrix using {self.method} approximation")
        
        # Initialize Fisher Information storage
        fisher_dict = {}
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                fisher_dict[name] = torch.zeros_like(param)
        
        # Set model to evaluation mode for Fisher computation
        self.model.eval()
        
        sample_count = 0
        for batch_idx, (x, y) in enumerate(dataloader):
            if sample_count >= num_samples:
                break
                
            # Forward pass
            logits = self.model(x)
            log_probs = F.log_softmax(logits, dim=-1)
            
            # Sample from predicted distribution (not ground truth)
            probs = F.softmax(logits, dim=-1)
            sampled_labels = torch.multinomial(probs, 1).squeeze()
            
            # Compute log-likelihood loss for sampled labels
            loss = F.nll_loss(log_probs, sampled_labels, reduction='mean')
            
            # Compute gradients
            grads = torch.autograd.grad(loss, self.model.parameters(), 
                                      create_graph=False, retain_graph=False)
            
            # Accumulate squared gradients (empirical Fisher Information)
            for (name, param), grad in zip(self.model.named_parameters(), grads):
                if param.requires_grad and grad is not None:
                    if self.method == "diagonal":
                        # Diagonal approximation: F_ii = (âˆ‚L/âˆ‚Î¸áµ¢)Â²
                        fisher_dict[name] += grad ** 2
                    elif self.method == "full":
                        # Full Fisher would require outer products - computationally expensive
                        # For now, fall back to diagonal
                        fisher_dict[name] += grad ** 2
                        
            sample_count += x.size(0)
        
        # Normalize by number of samples
        for name in fisher_dict:
            fisher_dict[name] /= sample_count
            
        # Apply numerical stability epsilon
        eps = 1e-8
        for name in fisher_dict:
            fisher_dict[name] += eps
            
        self.fisher_dict = fisher_dict
        
        # Compute parameter importance scores
        self._compute_importance_scores()
        
        logger.info(f"Fisher Information computed for {len(fisher_dict)} parameter groups")
        return fisher_dict
    
    def _compute_importance_scores(self):
        """Compute importance scores based on Fisher Information."""
        total_importance = 0
        for name, fisher in self.fisher_dict.items():
            total_importance += fisher.sum().item()
            
        for name, fisher in self.fisher_dict.items():
            # Normalize importance scores to sum to 1
            self.param_importance[name] = fisher.sum().item() / total_importance


class EpisodicMemoryBank:
    """
    Episodic memory bank for continual meta-learning.
    
    Stores representative examples from previous tasks to prevent
    catastrophic forgetting through experience replay.
    
    Based on:
    - "Episodic Memory in Lifelong Language Learning" (d'Autume et al. 2019)
    - "Gradient Episodic Memory for Continual Learning" (Lopez-Paz et al. 2017)
    """
    
    def __init__(self, memory_size: int = 1000, strategy: str = "reservoir"):
        self.memory_size = memory_size
        self.strategy = strategy
        self.memory_x = deque(maxlen=memory_size)
        self.memory_y = deque(maxlen=memory_size)
        self.memory_task_ids = deque(maxlen=memory_size)
        self.insertion_count = 0
        
    def add_examples(self, x: torch.Tensor, y: torch.Tensor, task_id: int):
        """Add examples to episodic memory using specified strategy."""
        batch_size = x.size(0)
        
        if self.strategy == "reservoir":
            # Reservoir sampling for unbiased sampling
            for i in range(batch_size):
                self.insertion_count += 1
                if len(self.memory_x) < self.memory_size:
                    # Memory not full, add directly
                    self.memory_x.append(x[i].clone())
                    self.memory_y.append(y[i].clone())
                    self.memory_task_ids.append(task_id)
                else:
                    # Reservoir sampling: replace with probability 1/insertion_count
                    j = np.random.randint(0, self.insertion_count)
                    if j < self.memory_size:
                        self.memory_x[j] = x[i].clone()
                        self.memory_y[j] = y[i].clone()  
                        self.memory_task_ids[j] = task_id
                        
        elif self.strategy == "random":
            # Simple random replacement
            for i in range(batch_size):
                if len(self.memory_x) < self.memory_size:
                    self.memory_x.append(x[i].clone())
                    self.memory_y.append(y[i].clone())
                    self.memory_task_ids.append(task_id)
                else:
                    # Random replacement
                    replace_idx = np.random.randint(0, self.memory_size)
                    self.memory_x[replace_idx] = x[i].clone()
                    self.memory_y[replace_idx] = y[i].clone()
                    self.memory_task_ids[replace_idx] = task_id
    
    def sample_batch(self, batch_size: int) -> Tuple[torch.Tensor, torch.Tensor, List[int]]:
        """Sample a batch from episodic memory."""
        if len(self.memory_x) == 0:
            return None, None, []
            
        # Sample indices
        indices = np.random.choice(len(self.memory_x), 
                                 size=min(batch_size, len(self.memory_x)), 
                                 replace=False)
        
        # Gather samples
        batch_x = torch.stack([self.memory_x[i] for i in indices])
        batch_y = torch.stack([self.memory_y[i] for i in indices])
        batch_task_ids = [self.memory_task_ids[i] for i in indices]
        
        return batch_x, batch_y, batch_task_ids
    
    def get_task_examples(self, task_id: int, max_examples: int = 100):
        """Get examples from a specific task."""
        task_x, task_y = [], []
        count = 0
        
        for i, tid in enumerate(self.memory_task_ids):
            if tid == task_id and count < max_examples:
                task_x.append(self.memory_x[i])
                task_y.append(self.memory_y[i])
                count += 1
                
        if task_x:
            return torch.stack(task_x), torch.stack(task_y)
        return None, None


class OnlineMetaLearner(nn.Module):
    """
    Online Meta-Learner for continual adaptation.
    
    Implements:
    1. Finn et al. (2019): "Online Meta-Learning"
    2. Nagabandi et al. (2019): "Learning to Adapt in Dynamic, Real-World Environments"
    3. Continual MAML with experience replay
    
    Key innovations:
    - Online parameter updates during deployment  
    - Episodic memory for anti-catastrophic forgetting
    - Fisher Information-based parameter importance
    - Task-agnostic meta-learning
    """
    
    def __init__(self, base_model: nn.Module, config: ContinualMetaConfig):
        super().__init__()
        self.base_model = base_model
        self.config = config
        
        # Initialize components
        self.fisher_computer = FisherInformationMatrix(base_model, config.ewc_method)
        self.memory_bank = EpisodicMemoryBank(config.memory_size, config.replay_strategy)
        
        # Store previous task parameters for EWC
        self.previous_params = {}
        self.fisher_information = {}
        
        # Task tracking
        self.current_task_id = 0
        self.task_boundaries = []
        
        # Meta-learning components
        self.meta_parameters = {}
        self.adaptation_lr = nn.Parameter(torch.tensor(config.adaptation_lr))
        self.consolidation_strength = nn.Parameter(torch.tensor(config.consolidation_strength))
        
        # Performance tracking
        self.task_performance = defaultdict(list)
        self.forgetting_metrics = defaultdict(float)
        
    def consolidate_task(self, dataloader, task_id: int):
        """
        Consolidate knowledge from current task before moving to next task.
        
        Implements Elastic Weight Consolidation (Kirkpatrick et al. 2017):
        1. Compute Fisher Information Matrix
        2. Store current parameters as "important" 
        3. Add consolidation loss for future tasks
        """
        logger.info(f"Consolidating knowledge for task {task_id}")
        
        # Compute Fisher Information Matrix
        fisher_dict = self.fisher_computer.compute_fisher(
            dataloader, self.config.fisher_samples
        )
        
        # Store current parameters as previous "important" parameters  
        previous_params = {}
        for name, param in self.base_model.named_parameters():
            if param.requires_grad:
                previous_params[name] = param.detach().clone()
                
        # Update stored information
        self.previous_params[task_id] = previous_params
        self.fisher_information[task_id] = fisher_dict
        
        # Update task boundary tracking
        self.task_boundaries.append(task_id)
        
        logger.info(f"Task {task_id} consolidated with {len(fisher_dict)} parameter groups")
    
    def compute_ewc_loss(self) -> torch.Tensor:
        """
        Compute Elastic Weight Consolidation loss.
        
        L_EWC = Î£â‚œ Î£áµ¢ (Î»â‚œ/2) * F_{t,i} * (Î¸áµ¢ - Î¸*_{t,i})Â²
        
        Where:
        - Î»â‚œ is task-specific consolidation strength
        - F_{t,i} is Fisher Information for parameter i from task t  
        - Î¸áµ¢ is current parameter value
        - Î¸*_{t,i} is stored important parameter value from task t
        """
        ewc_loss = 0.0
        
        for task_id in self.previous_params:
            previous_params = self.previous_params[task_id]
            fisher_info = self.fisher_information[task_id]
            
            for name, param in self.base_model.named_parameters():
                if name in previous_params and name in fisher_info:
                    # Compute parameter difference
                    param_diff = param - previous_params[name]
                    
                    # Weight by Fisher Information (importance)
                    fisher_weight = fisher_info[name]
                    
                    # EWC loss: (Î»/2) * F_i * (Î¸áµ¢ - Î¸*áµ¢)Â²
                    task_ewc_loss = (fisher_weight * param_diff ** 2).sum()
                    ewc_loss += task_ewc_loss
        
        # Scale by consolidation strength
        ewc_loss *= self.consolidation_strength / 2.0
        
        return ewc_loss
    
    def replay_previous_tasks(self, current_loss: torch.Tensor, 
                            replay_batch_size: int = 32) -> torch.Tensor:
        """
        Experience replay to prevent catastrophic forgetting.
        
        Samples from episodic memory and computes loss on previous examples.
        """
        # Sample from memory bank
        mem_x, mem_y, mem_task_ids = self.memory_bank.sample_batch(replay_batch_size)
        
        if mem_x is None:
            return current_loss
        
        # Forward pass on memory examples
        mem_logits = self.base_model(mem_x)
        replay_loss = F.cross_entropy(mem_logits, mem_y)
        
        # Combine current task loss with replay loss
        combined_loss = current_loss + self.config.forgetting_factor * replay_loss
        
        return combined_loss
    
    def fast_adaptation(self, support_x: torch.Tensor, support_y: torch.Tensor,
                       query_x: torch.Tensor, query_y: torch.Tensor,
                       adaptation_steps: int = None) -> Tuple[torch.Tensor, Dict]:
        """
        Fast adaptation to new task using meta-learned initialization.
        
        Implements MAML-style adaptation with continual learning modifications:
        1. Inner loop: Î¸' = Î¸ - Î± * âˆ‡L_support(Î¸) 
        2. Add EWC regularization to prevent forgetting
        3. Use episodic memory for experience replay
        """
        if adaptation_steps is None:
            adaptation_steps = self.config.adaptation_steps
            
        # Store original parameters
        original_params = {}
        for name, param in self.base_model.named_parameters():
            original_params[name] = param.detach().clone()
        
        adaptation_losses = []
        
        # Inner loop adaptation
        for step in range(adaptation_steps):
            # Forward pass on support set
            support_logits = self.base_model(support_x)
            support_loss = F.cross_entropy(support_logits, support_y)
            
            # Add EWC regularization
            ewc_loss = self.compute_ewc_loss()
            
            # Add experience replay
            total_loss = self.replay_previous_tasks(support_loss)
            total_loss += ewc_loss
            
            # Gradient update
            self.base_model.zero_grad()
            total_loss.backward()
            
            # Manual gradient descent with learned learning rate
            with torch.no_grad():
                for param in self.base_model.parameters():
                    if param.grad is not None:
                        param -= self.adaptation_lr * param.grad
            
            adaptation_losses.append(total_loss.item())
        
        # Forward pass on query set with adapted parameters
        query_logits = self.base_model(query_x)
        query_loss = F.cross_entropy(query_logits, query_y)
        
        # Compute accuracy
        with torch.no_grad():
            query_pred = query_logits.argmax(dim=-1)
            query_acc = (query_pred == query_y).float().mean()
        
        # Restore original parameters
        with torch.no_grad():
            for name, param in self.base_model.named_parameters():
                param.copy_(original_params[name])
        
        metrics = {
            'adaptation_losses': adaptation_losses,
            'query_loss': query_loss.item(),
            'query_accuracy': query_acc.item(),
            'ewc_loss': ewc_loss.item() if isinstance(ewc_loss, torch.Tensor) else ewc_loss
        }
        
        return query_loss, metrics
    
    def continual_update(self, x: torch.Tensor, y: torch.Tensor, 
                        task_id: int) -> Dict[str, float]:
        """
        Perform continual learning update on new data.
        
        1. Add examples to episodic memory
        2. Compute loss with EWC regularization  
        3. Update model parameters
        4. Track performance metrics
        """
        # Add to episodic memory
        self.memory_bank.add_examples(x, y, task_id)
        
        # Forward pass
        logits = self.base_model(x)
        task_loss = F.cross_entropy(logits, y)
        
        # Add EWC regularization
        ewc_loss = self.compute_ewc_loss()
        
        # Add experience replay
        total_loss = self.replay_previous_tasks(task_loss)
        total_loss += ewc_loss
        
        # Compute metrics
        with torch.no_grad():
            pred = logits.argmax(dim=-1)
            accuracy = (pred == y).float().mean()
        
        # Store performance for this task
        self.task_performance[task_id].append(accuracy.item())
        
        metrics = {
            'task_loss': task_loss.item(),
            'ewc_loss': ewc_loss.item() if isinstance(ewc_loss, torch.Tensor) else ewc_loss,
            'total_loss': total_loss.item(),
            'accuracy': accuracy.item(),
            'memory_size': len(self.memory_bank.memory_x)
        }
        
        return total_loss, metrics
    
    def evaluate_on_previous_tasks(self, task_data: Dict[int, Tuple]) -> Dict[str, float]:
        """
        Evaluate model on previous tasks to measure forgetting.
        
        Returns backward transfer metrics and forgetting measurements.
        """
        self.base_model.eval()
        results = {}
        
        with torch.no_grad():
            for task_id, (test_x, test_y) in task_data.items():
                if task_id in self.task_boundaries:
                    logits = self.base_model(test_x)
                    loss = F.cross_entropy(logits, test_y)
                    pred = logits.argmax(dim=-1)
                    accuracy = (pred == test_y).float().mean()
                    
                    results[f'task_{task_id}_loss'] = loss.item()
                    results[f'task_{task_id}_accuracy'] = accuracy.item()
                    
                    # Compute forgetting metric
                    if task_id in self.task_performance and len(self.task_performance[task_id]) > 0:
                        best_performance = max(self.task_performance[task_id])
                        current_performance = accuracy.item()
                        forgetting = best_performance - current_performance
                        results[f'task_{task_id}_forgetting'] = forgetting
                        self.forgetting_metrics[task_id] = forgetting
        
        # Compute average forgetting
        if self.forgetting_metrics:
            results['average_forgetting'] = np.mean(list(self.forgetting_metrics.values()))
        
        self.base_model.train()
        return results
    
    def save_state(self, filepath: str):
        """Save the complete continual learning state."""
        state = {
            'model_state_dict': self.base_model.state_dict(),
            'previous_params': self.previous_params,
            'fisher_information': self.fisher_information,
            'task_boundaries': self.task_boundaries,
            'current_task_id': self.current_task_id,
            'task_performance': dict(self.task_performance),
            'forgetting_metrics': dict(self.forgetting_metrics),
            'config': self.config,
            # Note: Memory bank contains tensors, would need special handling for full save
        }
        torch.save(state, filepath)
        logger.info(f"Continual learning state saved to {filepath}")
    
    def load_state(self, filepath: str):
        """Load the complete continual learning state."""
        state = torch.load(filepath)
        self.base_model.load_state_dict(state['model_state_dict'])
        self.previous_params = state['previous_params']
        self.fisher_information = state['fisher_information']
        self.task_boundaries = state['task_boundaries']
        self.current_task_id = state['current_task_id']
        self.task_performance = defaultdict(list, state['task_performance'])
        self.forgetting_metrics = defaultdict(float, state['forgetting_metrics'])
        logger.info(f"Continual learning state loaded from {filepath}")


def create_continual_meta_learner(model: nn.Module, 
                                config: Optional[ContinualMetaConfig] = None) -> OnlineMetaLearner:
    """
    Factory function to create a continual meta-learner.
    
    Args:
        model: Base neural network to wrap
        config: Configuration for continual learning
        
    Returns:
        Configured continual meta-learner
    """
    if config is None:
        config = ContinualMetaConfig()
    
    return OnlineMetaLearner(model, config)


# Utility functions for continual learning evaluation
def compute_forgetting_metrics(task_performances: Dict[int, List[float]]) -> Dict[str, float]:
    """
    Compute comprehensive forgetting metrics.
    
    Metrics:
    - Backward Transfer: Performance change on previous tasks
    - Forgetting: Maximum performance drop on previous tasks  
    - Intransigence: Inability to learn new tasks
    """
    metrics = {}
    
    # Compute forgetting for each task
    task_forgetting = {}
    for task_id, performances in task_performances.items():
        if len(performances) > 1:
            max_performance = max(performances)
            final_performance = performances[-1]
            forgetting = max_performance - final_performance
            task_forgetting[task_id] = forgetting
    
    if task_forgetting:
        metrics['average_forgetting'] = np.mean(list(task_forgetting.values()))
        metrics['max_forgetting'] = max(task_forgetting.values())
        metrics['forgetting_std'] = np.std(list(task_forgetting.values()))
    
    return metrics


def benchmark_continual_learning(model: nn.Module, 
                                task_sequence: List[Tuple],
                                config: Optional[ContinualMetaConfig] = None) -> Dict[str, Any]:
    """
    Benchmark continual learning performance on a sequence of tasks.
    
    Args:
        model: Base model to evaluate
        task_sequence: List of (train_data, test_data, task_id) tuples
        config: Continual learning configuration
        
    Returns:
        Comprehensive benchmark results
    """
    learner = create_continual_meta_learner(model, config)
    results = {
        'task_performances': defaultdict(list),
        'adaptation_curves': {},
        'memory_usage': [],
        'consolidation_times': []
    }
    
    # Process each task in sequence
    for task_idx, (train_data, test_data, task_id) in enumerate(task_sequence):
        logger.info(f"Processing task {task_id} ({task_idx + 1}/{len(task_sequence)})")
        
        # Training phase - continual updates
        train_x, train_y = train_data
        adaptation_metrics = []
        
        for batch_start in range(0, len(train_x), 32):
            batch_end = min(batch_start + 32, len(train_x))
            batch_x = train_x[batch_start:batch_end]
            batch_y = train_y[batch_start:batch_end]
            
            loss, metrics = learner.continual_update(batch_x, batch_y, task_id)
            adaptation_metrics.append(metrics)
        
        results['adaptation_curves'][task_id] = adaptation_metrics
        
        # Evaluation phase
        test_x, test_y = test_data
        with torch.no_grad():
            test_logits = learner.base_model(test_x)
            test_pred = test_logits.argmax(dim=-1)  
            test_acc = (test_pred == test_y).float().mean().item()
            
        results['task_performances'][task_id].append(test_acc)
        
        # Consolidation phase (if not last task)
        if task_idx < len(task_sequence) - 1:
            # Create dataloader for consolidation
            from torch.utils.data import TensorDataset, DataLoader
            dataset = TensorDataset(train_x, train_y)
            dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
            
            import time
            consolidation_start = time.time()
            learner.consolidate_task(dataloader, task_id)
            consolidation_time = time.time() - consolidation_start
            results['consolidation_times'].append(consolidation_time)
        
        # Memory tracking
        results['memory_usage'].append(len(learner.memory_bank.memory_x))
        
        logger.info(f"Task {task_id} completed. Accuracy: {test_acc:.4f}")
    
    # Compute final metrics
    results['forgetting_metrics'] = compute_forgetting_metrics(results['task_performances'])
    results['final_model_state'] = learner.base_model.state_dict()
    
    return results


if __name__ == "__main__":
    # Example usage and testing
    print("Continual Meta-Learning Module Test")
    print("=" * 50)
    
    # Create a simple test model
    model = nn.Sequential(
        nn.Linear(10, 20),
        nn.ReLU(),
        nn.Linear(20, 5)
    )
    
    # Test configuration
    config = ContinualMetaConfig(
        memory_size=100,
        adaptation_lr=0.01,
        consolidation_strength=1000.0,
        ewc_method="diagonal"
    )
    
    # Create continual learner
    learner = create_continual_meta_learner(model, config)
    
    print(f"âœ“ Created continual meta-learner with {config.memory_size} memory size")
    print(f"âœ“ EWC method: {config.ewc_method}")
    print(f"âœ“ Adaptation LR: {config.adaptation_lr}")
    
    # Test fast adaptation
    support_x = torch.randn(25, 10)  # 5-way 5-shot
    support_y = torch.randint(0, 5, (25,))
    query_x = torch.randn(50, 10)   # 5-way 10-query
    query_y = torch.randint(0, 5, (50,))
    
    query_loss, metrics = learner.fast_adaptation(support_x, support_y, query_x, query_y)
    
    print(f"âœ“ Fast adaptation completed")
    print(f"  Query loss: {metrics['query_loss']:.4f}")
    print(f"  Query accuracy: {metrics['query_accuracy']:.4f}")
    print(f"  EWC loss: {metrics['ewc_loss']:.4f}")
    
    # Test continual update
    new_x = torch.randn(16, 10)
    new_y = torch.randint(0, 5, (16,))
    
    cont_loss, cont_metrics = learner.continual_update(new_x, new_y, task_id=1)
    
    print(f"âœ“ Continual update completed")
    print(f"  Task accuracy: {cont_metrics['accuracy']:.4f}")
    print(f"  Memory size: {cont_metrics['memory_size']}")
    
    print("\nâœ“ All continual meta-learning tests passed!")